<!DOCTYPE html><html lang="en"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="我答应了十八岁的自己不会变"><title>部署Hadoop集群 | SilverBullet</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=1.0.0"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/normalize.css/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/purecss/build/pure-min.min.css"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/purecss/build/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.jsdelivr.net/npm/jquery/dist/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><script type="text/javascript" src="//cdn.jsdelivr.net/npm/clipboard/dist/clipboard.min.js"></script><script type="text/javascript" src="//cdn.jsdelivr.net/gh/codeseven/toastr/build/toastr.min.js"></script><link rel="stylesheet" href="//cdn.jsdelivr.net/gh/codeseven/toastr/build/toastr.min.css"><meta name="generator" content="Hexo 5.4.0"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">部署Hadoop集群</h1><a id="logo" href="/.">SilverBullet</a><p class="description">说点自己想说的话</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> Home</i></a><a href="/archives/"><i class="fa fa-archive"> Archive</i></a><a href="/about/"><i class="fa fa-user"> About</i></a><a href="/atom.xml"><i class="fa fa-rss"> RSS</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">部署Hadoop集群</h1><div class="post-meta">2019-09-30</div><div class="clear"><div class="toc-article" id="toc"><div class="toc-title">Contents</div><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%89%8D%E8%A8%80"><span class="toc-number">1.</span> <span class="toc-text">前言</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%8E%AF%E5%A2%83"><span class="toc-number">2.</span> <span class="toc-text">环境</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BF%AE%E6%94%B9host%E6%96%87%E4%BB%B6"><span class="toc-number">3.</span> <span class="toc-text">修改host文件</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%85%8D%E7%BD%AESSH"><span class="toc-number">4.</span> <span class="toc-text">配置SSH</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%85%8D%E7%BD%AEHadoop"><span class="toc-number">5.</span> <span class="toc-text">配置Hadoop</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%8E%B7%E5%8F%96Hadoop"><span class="toc-number">5.1.</span> <span class="toc-text">获取Hadoop</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BF%AE%E6%94%B9%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="toc-number">5.2.</span> <span class="toc-text">修改配置文件</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#hadoop-env-sh"><span class="toc-number">5.2.1.</span> <span class="toc-text">hadoop-env.sh</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#core-site-xml"><span class="toc-number">5.2.2.</span> <span class="toc-text">core-site.xml</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#mapred-site-xml"><span class="toc-number">5.2.3.</span> <span class="toc-text">mapred-site.xml</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#yarn-site-xml"><span class="toc-number">5.2.4.</span> <span class="toc-text">yarn-site.xml</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#hdfs-site-xml"><span class="toc-number">5.2.5.</span> <span class="toc-text">hdfs-site.xml</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#workers"><span class="toc-number">5.2.6.</span> <span class="toc-text">workers</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%83%A8%E7%BD%B2Hadoop"><span class="toc-number">5.3.</span> <span class="toc-text">部署Hadoop</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%90%AF%E5%8A%A8Hadoop"><span class="toc-number">5.4.</span> <span class="toc-text">启动Hadoop</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%85%8D%E7%BD%AEHbase"><span class="toc-number">6.</span> <span class="toc-text">配置Hbase</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%8E%B7%E5%8F%96Hbase"><span class="toc-number">6.1.</span> <span class="toc-text">获取Hbase</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F"><span class="toc-number">6.2.</span> <span class="toc-text">配置环境变量</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BF%AE%E6%94%B9%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%EF%BC%88conf%E6%96%87%E4%BB%B6%E5%A4%B9%E4%B8%8B%EF%BC%89"><span class="toc-number">6.3.</span> <span class="toc-text">修改配置文件（conf文件夹下）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#hbase-env-sh"><span class="toc-number">6.3.1.</span> <span class="toc-text">hbase-env.sh</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#hbase-site-xml"><span class="toc-number">6.3.2.</span> <span class="toc-text">hbase-site.xml</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#regionservers"><span class="toc-number">6.3.3.</span> <span class="toc-text">regionservers</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%83%A8%E7%BD%B2Hbase"><span class="toc-number">6.4.</span> <span class="toc-text">部署Hbase</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%90%AF%E5%8A%A8Hbase"><span class="toc-number">6.5.</span> <span class="toc-text">启动Hbase</span></a></li></ol></li></ol></div></div><div class="post-content"><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>适逢非关系数据库老师布置了课后作业，要我们搭建一个Hbase和MongoDB数据库，而我又得知Hbase可以通过集群搭建提高性能，所以我打算在自己的桌面环境下尝试一下，过程中遇到的一些问题，我会记录在这里。</p>
<span id="more"></span>

<h1 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h1><ul>
<li><p>OS : Ubuntu 16.04</p>
</li>
<li><p>JDK : 1.8</p>
</li>
<li><p>Hadoop : 3.2.1</p>
<table>
<thead>
<tr>
<th align="center">服务器</th>
<th align="center">IP地址</th>
</tr>
</thead>
<tbody><tr>
<td align="center">hadoop-master</td>
<td align="center">192.168.41.141</td>
</tr>
<tr>
<td align="center">hadoop-node01</td>
<td align="center">192.168.41.142</td>
</tr>
<tr>
<td align="center">hadoop-node02</td>
<td align="center">192.168.41.143</td>
</tr>
</tbody></table>
</li>
</ul>
<h1 id="修改host文件"><a href="#修改host文件" class="headerlink" title="修改host文件"></a>修改host文件</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vi /etc/hosts</span><br></pre></td></tr></table></figure>

<p>加入如下几行：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">192.168.41.141  hadoop-master</span><br><span class="line">192.168.41.142  hadoop-node01</span><br><span class="line">192.168.41.143  hadoop-node02</span><br></pre></td></tr></table></figure>

<p>三台服务器的host文件都需要修改，修改之后运行命令<code>source /etc/hosts</code>使其生效。</p>
<h1 id="配置SSH"><a href="#配置SSH" class="headerlink" title="配置SSH"></a>配置SSH</h1><p>首先需要通过创建SSH实现三台服务器之间的免密登陆。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa</span><br></pre></td></tr></table></figure>

<p>生成的公钥保存在<code>～/.ssh</code>下，此时需要把公钥放入<code>authorized_keys</code>，命令如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat ～/.ssh/id_rsa.pub &gt; ~/.ssh/authorized_keys</span><br></pre></td></tr></table></figure>

<p>之后，我们应该在另外两台服务器上创建SSH，并且将自己服务器上的公钥放入Master服务器的<code>authorized_keys</code>里，实现三台服务器之间的免密登陆。</p>
<p>这里我为了方便，我直接将<code>~/.ssh</code>复制到了另外两台服务器的<code>~/</code>位置：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scp -r ~/.ssh root@hadoop-node01:~/.ssh</span><br><span class="line">scp -r ~/.ssh root@hadoop-node02:~/.ssh</span><br></pre></td></tr></table></figure>

<p>通过如下命令即可验证配置成功：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">root@hadoop-master:/<span class="comment"># ssh hadoop-node01</span></span><br><span class="line">Welcome to Ubuntu 16.04 LTS (GNU/Linux 4.4.0-21-generic x86_64)</span><br><span class="line"></span><br><span class="line"> * Documentation:  https://help.ubuntu.com/</span><br><span class="line"></span><br><span class="line">234 packages can be updated.</span><br><span class="line">149 updates are security updates.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Last login: Mon Sep 30 11:09:53 2019 from ::1</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="配置Hadoop"><a href="#配置Hadoop" class="headerlink" title="配置Hadoop"></a>配置Hadoop</h1><h2 id="获取Hadoop"><a href="#获取Hadoop" class="headerlink" title="获取Hadoop"></a>获取Hadoop</h2><p>运行命令</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https://mirrors.tuna.tsinghua.edu.cn/apache/hadoop/common/stable/hadoop-3.2.1-src.tar.gz</span><br></pre></td></tr></table></figure>

<p>解压</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf hadoop-3.2.1-src.tar.gz </span><br></pre></td></tr></table></figure>

<h2 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h2><h3 id="hadoop-env-sh"><a href="#hadoop-env-sh" class="headerlink" title="hadoop-env.sh"></a>hadoop-env.sh</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vi hadoop-env.sh</span><br><span class="line">//添加JDK安装路径</span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/<span class="built_in">local</span>/jdk/jdk1.8.0_221/</span><br></pre></td></tr></table></figure>

<h3 id="core-site-xml"><a href="#core-site-xml" class="headerlink" title="core-site.xml"></a>core-site.xml</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">vi core-site.xml</span><br><span class="line">//添加如下配置</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">//文件系统用HDFS</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;fs.default.name&lt;/name&gt;</span><br><span class="line">//namenode的地址</span><br><span class="line">&lt;value&gt;hdfs://hadoop-master:9000&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">//临时文件的存放路径</span><br><span class="line">&lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span><br><span class="line">&lt;value&gt;/root/hadoop/hdfs/tmp&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>



<h3 id="mapred-site-xml"><a href="#mapred-site-xml" class="headerlink" title="mapred-site.xml"></a>mapred-site.xml</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">vi mapred-site.xml</span><br><span class="line"></span><br><span class="line">//添加如下配置</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">//配置mapreduce运行的平台，默认为<span class="built_in">local</span>本地平台模拟运行，而不是在集群上分布式运行，只是一个单机的程序，这里配置yarn平台运行，负责分配内存</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span><br><span class="line">&lt;value&gt;yarn&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;       </span><br></pre></td></tr></table></figure>

<h3 id="yarn-site-xml"><a href="#yarn-site-xml" class="headerlink" title="yarn-site.xml"></a>yarn-site.xml</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">vi yarn-site.xml</span><br><span class="line"></span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">//指定yarn的resourcemanager地址</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;yarn.resourcecemanager.hostname&lt;/name&gt;</span><br><span class="line">&lt;value&gt;hadoop-master&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">//reducer获取数据方式</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span><br><span class="line">&lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">//忽略虚拟内存的检查，如果是在实体机上，并且内存够多，可以去掉</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;yarn.nodemanager.vmem-check-enabled&lt;/name&gt;</span><br><span class="line">&lt;value&gt;<span class="literal">false</span>&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>

<h3 id="hdfs-site-xml"><a href="#hdfs-site-xml" class="headerlink" title="hdfs-site.xml"></a>hdfs-site.xml</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">//添加如下内容</span><br><span class="line"></span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">//hdfs的副本数量</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;dfs.replication&lt;/name&gt;</span><br><span class="line">&lt;value&gt;2&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">//Hadoop NameNode运行端口，在通过192.168.41.141：50070访问</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;dfs.namenode.http-address&lt;/name&gt;</span><br><span class="line">&lt;value&gt;hadoop-master:50070&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">//存储上传数据的路径</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;dfs.name.dir&lt;/name&gt;</span><br><span class="line">&lt;value&gt;/root/hadoop/hdfs/data&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">//存储namenode的路径</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;dfs.name.dir&lt;/name&gt;</span><br><span class="line">&lt;value&gt;/root/hadoop/hdfs/name&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">//设置为<span class="literal">false</span>可以不用检查路径</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;dfs.permissions&lt;/name&gt;</span><br><span class="line">&lt;value&gt;<span class="literal">false</span>&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="workers"><a href="#workers" class="headerlink" title="workers"></a>workers</h3><p>在Hadoop:2.9.1版本中，该配置文件为<code>slaves</code>，但是在3.2版本中，文件更名为<code>workers</code>，在部署过程中，这里尤其要注意，我就是因为没有注意，在master上开启Hadoop后，Node节点上并没有相继运行<code>datanode</code>和<code>nodemanager</code>。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vi workers</span><br><span class="line"></span><br><span class="line">//添加如下内容</span><br><span class="line">hadoop-node01</span><br><span class="line">hadoop-node02</span><br></pre></td></tr></table></figure>

<h2 id="部署Hadoop"><a href="#部署Hadoop" class="headerlink" title="部署Hadoop"></a>部署Hadoop</h2><p>将修改后的Hadoop文件夹拷贝至Node01、Node02节点上：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scp -r /root/hadoop root@hadoop-node01:/root/</span><br><span class="line">scp -r /root/hadoop root@hadoop-node02:/root/</span><br></pre></td></tr></table></figure>

<p>并且修改环境变量，添加如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/profile</span><br><span class="line"></span><br><span class="line">//添加如下</span><br><span class="line"><span class="built_in">export</span> HADOOP_HOME=~/hadoop/</span><br><span class="line"><span class="built_in">export</span> HADOOP_COMMON_LIB_NATIVE_DIR=<span class="variable">$HADOOP_HOME</span>/lib/native</span><br><span class="line"><span class="built_in">export</span> HADOOP_OPTS=-Djava.library.path=<span class="variable">$HADOOP_HOME</span>/lib</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$JAVA_HOME</span>/bin:<span class="variable">$JAVA_HOME</span>/jre/bin:<span class="variable">$PATH</span>:<span class="variable">$HOME</span>/bin:<span class="variable">$HADOOP_HOME</span>/bin:<span class="variable">$HADOOP_HOME</span>/sbin</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="启动Hadoop"><a href="#启动Hadoop" class="headerlink" title="启动Hadoop"></a>启动Hadoop</h2><p>执行<code>start-all.sh</code>启动Hadoop：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">root@hadoop-master:~/hadoop/etc/hadoop<span class="comment"># start-all.sh </span></span><br><span class="line">Starting namenodes on [hadoop-master]</span><br><span class="line">Starting datanodes</span><br><span class="line">Starting secondary namenodes [hadoop-master]</span><br><span class="line">2019-09-30 19:10:07,637 WARN util.NativeCodeLoader: Unable to load native-hadoop library <span class="keyword">for</span> your platform... using builtin-java classes <span class="built_in">where</span> applicable</span><br><span class="line">Starting resourcemanager</span><br><span class="line">Starting nodemanagers</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>在Master节点上可以通过执行<code>jps</code>命令查看启动的进程：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">root@hadoop-master:~/hadoop/etc/hadoop<span class="comment"># jps</span></span><br><span class="line">20241 Jps</span><br><span class="line">19857 SecondaryNameNode</span><br><span class="line">126115 NodeManager</span><br><span class="line">125540 DataNode</span><br><span class="line">20088 ResourceManager</span><br><span class="line">19626 NameNode</span><br></pre></td></tr></table></figure>

<p>Node节点上：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">root@hadoop-node01:~/hadoop/etc/hadoop<span class="comment"># jps</span></span><br><span class="line">122113 NodeManager</span><br><span class="line">121974 DataNode</span><br><span class="line">122942 Jps</span><br></pre></td></tr></table></figure>

<p>至此，Hadoop部署成功。</p>
<p>可以在通过访问192.168.41.141:50070访问web页面：</p>
<p><img src="Hadoop-build/hadoop-web.png" alt="hadoop-web"></p>
<h1 id="配置Hbase"><a href="#配置Hbase" class="headerlink" title="配置Hbase"></a>配置Hbase</h1><h2 id="获取Hbase"><a href="#获取Hbase" class="headerlink" title="获取Hbase"></a>获取Hbase</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget http://mirror.bit.edu.cn/apache/hbase/2.2.1/hbase-2.2.1-bin.tar.gz  </span><br></pre></td></tr></table></figure>

<p>解压</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf hbase-2.2.1-bin.tar.gz  </span><br></pre></td></tr></table></figure>

<p>重命名</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mv hbase-2.2.1 hbase </span><br></pre></td></tr></table></figure>

<h2 id="配置环境变量"><a href="#配置环境变量" class="headerlink" title="配置环境变量"></a>配置环境变量</h2><p>把Hbase的路径添加到环境变量中：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/profile</span><br><span class="line"></span><br><span class="line">//添加如下</span><br><span class="line"><span class="built_in">export</span> HBASE_HOME=/home/wang/hbase</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$HBASE_HOME</span>/bin:<span class="variable">$PATH</span></span><br></pre></td></tr></table></figure>

<p>运行<code>source /etc/profile</code>使之生效。</p>
<h2 id="修改配置文件（conf文件夹下）"><a href="#修改配置文件（conf文件夹下）" class="headerlink" title="修改配置文件（conf文件夹下）"></a>修改配置文件（conf文件夹下）</h2><h3 id="hbase-env-sh"><a href="#hbase-env-sh" class="headerlink" title="hbase-env.sh"></a>hbase-env.sh</h3><p>修改如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># The java implementation to use.  Java 1.8+ required.</span></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/<span class="built_in">local</span>/jdk/jdk1.8.0_221</span><br><span class="line"></span><br><span class="line"><span class="comment"># Extra Java CLASSPATH elements.  Optional.</span></span><br><span class="line"><span class="built_in">export</span> JAVA_CLASSPATH=<span class="variable">$JAVA_HOME</span>/lib/dt.jar:<span class="variable">$JAVA_HOME</span>/lib/tools.jar</span><br><span class="line"><span class="comment"># Where log files are stored.  $HBASE_HOME/logs by default.</span></span><br><span class="line"><span class="built_in">export</span> HBASE_LOG_DIR=/root/hbase/logs</span><br><span class="line"><span class="comment"># Tell HBase whether it should manage it&#x27;s own instance of ZooKeeper or not.</span></span><br><span class="line"><span class="built_in">export</span> HBASE_MANAGES_ZK=tru</span><br></pre></td></tr></table></figure>

<h3 id="hbase-site-xml"><a href="#hbase-site-xml" class="headerlink" title="hbase-site.xml"></a>hbase-site.xml</h3><p>修改如下：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.master<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop-master:6000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.rootdir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://hadoop-master:9000/hbase<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.cluster.distributed<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>/root/hbase/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.zookeeper.property.dataDir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>/root/zookeeper<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.zookeeper.quorum<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop-master,hadoop-node01,hadoop-node02<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h3 id="regionservers"><a href="#regionservers" class="headerlink" title="regionservers"></a>regionservers</h3><p>修改如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop-node01</span><br><span class="line">hadoop-node02</span><br></pre></td></tr></table></figure>

<h2 id="部署Hbase"><a href="#部署Hbase" class="headerlink" title="部署Hbase"></a>部署Hbase</h2><p>将修改后的Hbase文件夹拷贝至Node01、Node02节点上：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scp -r /root/hbase root@hadoop-node01:/root/</span><br><span class="line">scp -r /root/hbase root@hadoop-node02:/root/</span><br></pre></td></tr></table></figure>

<p>并且修改环境变量。</p>
<h2 id="启动Hbase"><a href="#启动Hbase" class="headerlink" title="启动Hbase"></a>启动Hbase</h2><p>执行<code>start-hbse.sh</code>启动Hbase：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">root@hadoop-master:~/zookeeper<span class="comment"># start-hbase.sh </span></span><br><span class="line">SLF4J: Class path contains multiple SLF4J bindings.</span><br><span class="line">SLF4J: Found binding <span class="keyword">in</span> [jar:file:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class</span><br><span class="line">SLF4J: Found binding <span class="keyword">in</span> [jar:file:/root/hbase/lib/client-facing-thirdparty/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.</span><br><span class="line">SLF4J: See http://www.slf4j.org/codes.html<span class="comment">#multiple_bindings for an explanation.</span></span><br><span class="line">SLF4J: Actual binding is of <span class="built_in">type</span> [org.slf4j.impl.Log4jLoggerFactory]</span><br><span class="line">SLF4J: Class path contains multiple SLF4J bindings.</span><br><span class="line">SLF4J: Found binding <span class="keyword">in</span> [jar:file:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class</span><br><span class="line">SLF4J: Found binding <span class="keyword">in</span> [jar:file:/root/hbase/lib/client-facing-thirdparty/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.</span><br><span class="line">SLF4J: See http://www.slf4j.org/codes.html<span class="comment">#multiple_bindings for an explanation.</span></span><br><span class="line">SLF4J: Actual binding is of <span class="built_in">type</span> [org.slf4j.impl.Log4jLoggerFactory]</span><br><span class="line">hadoop-master: running zookeeper, logging to /root/hbase/logs/hbase-root-zookeeper-hadoop-master.out</span><br><span class="line">hadoop-node02: running zookeeper, logging to /root/hbase/logs/hbase-root-zookeeper-hadoop-node02.out</span><br><span class="line">hadoop-node01: running zookeeper, logging to /root/hbase/logs/hbase-root-zookeeper-hadoop-node01.out</span><br><span class="line">running master, logging to /root/hbase/logs/hbase-root-master-hadoop-master.out</span><br><span class="line">hadoop-node01: running regionserver, logging to /root/hbase/logs/hbase-root-regionserver-hadoop-node01.out</span><br><span class="line">hadoop-node02: running regionserver, logging to /root/hbase/logs/hbase-root-regionserver-hadoop-node02.out</span><br></pre></td></tr></table></figure>

<p>运行bash shell：</p>
<p><img src="Hadoop-build/bash-shell.png" alt="bash-shell"></p>
<p>至此，集群下的Hbase搭建完成。</p>
</div><div class="tags"><a href="/tags/Hadoop/"><i class="fa fa-tag"></i>Hadoop</a><a href="/tags/NoSQL/"><i class="fa fa-tag"></i>NoSQL</a><a href="/tags/Hbase/"><i class="fa fa-tag"></i>Hbase</a></div><div class="post-nav"><a class="pre" href="/2019/09/30/MongoDB-build/">MongoDB在Windows环境下部署</a><a class="next" href="/2019/07/17/Extract-NianShaoHuangTang/">摘阅：《年少荒唐》 - 朱炫</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="http://example.com"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> Categories</i></div></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> Tags</i></div><div class="tagcloud"><a href="/tags/%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93/" style="font-size: 15px;">年度总结</a> <a href="/tags/%E9%9A%8F%E7%AC%94/" style="font-size: 15px;">随笔</a> <a href="/tags/%E6%91%98%E9%98%85/" style="font-size: 15px;">摘阅</a> <a href="/tags/Docker/" style="font-size: 15px;">Docker</a> <a href="/tags/Gitlab/" style="font-size: 15px;">Gitlab</a> <a href="/tags/Spring-Cloud/" style="font-size: 15px;">Spring Cloud</a> <a href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83/" style="font-size: 15px;">分布式配置中心</a> <a href="/tags/Help/" style="font-size: 15px;">Help</a> <a href="/tags/Compose/" style="font-size: 15px;">Compose</a> <a href="/tags/Eureka/" style="font-size: 15px;">Eureka</a> <a href="/tags/%E9%AB%98%E5%8F%AF%E7%94%A8/" style="font-size: 15px;">高可用</a> <a href="/tags/%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6/" style="font-size: 15px;">版本控制</a> <a href="/tags/%E8%BF%9C%E7%A8%8B%E4%BB%93%E5%BA%93/" style="font-size: 15px;">远程仓库</a> <a href="/tags/Hadoop/" style="font-size: 15px;">Hadoop</a> <a href="/tags/NoSQL/" style="font-size: 15px;">NoSQL</a> <a href="/tags/Hbase/" style="font-size: 15px;">Hbase</a> <a href="/tags/MongoDB/" style="font-size: 15px;">MongoDB</a> <a href="/tags/Qt/" style="font-size: 15px;">Qt</a> <a href="/tags/%E4%B8%8A%E4%BD%8D%E6%9C%BA/" style="font-size: 15px;">上位机</a> <a href="/tags/%E5%B5%8C%E5%85%A5%E5%BC%8F/" style="font-size: 15px;">嵌入式</a> <a href="/tags/%E6%91%98%E5%BD%95/" style="font-size: 15px;">摘录</a> <a href="/tags/Wordpress/" style="font-size: 15px;">Wordpress</a> <a href="/tags/hexo/" style="font-size: 15px;">hexo</a> <a href="/tags/Apollo/" style="font-size: 15px;">Apollo</a> <a href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F/" style="font-size: 15px;">分布式</a> <a href="/tags/Kubernetes/" style="font-size: 15px;">Kubernetes</a> <a href="/tags/%E7%AC%94%E8%AE%B0/" style="font-size: 15px;">笔记</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> Recent</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2020/12/31/2020Report/">2020Report</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/12/17/vuex_DOC/">vuex_DOC</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/10/01/LogMonitor/">LogMonitor</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/09/07/K8s_client/">K8s_client</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/09/06/Springcloud_zipkin/">Springcloud_zipkin</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/09/06/Extract_2020_2_6/">Extract_2020_2_6</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/01/12/2019Report/">2019Report</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/20/Dairy_2019_11_20/">Dairy_2019_11_20</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/05/ghost-valine/">ghost-valine</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/05/ghost-deploy/">ghost-deploy</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> Links</i></div><ul></ul><a href="http://www.example1.com/" title="site-name1" target="_blank">site-name1</a><ul></ul><a href="http://www.example2.com/" title="site-name2" target="_blank">site-name2</a><ul></ul><a href="http://www.example3.com/" title="site-name3" target="_blank">site-name3</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2021 <a href="/." rel="nofollow">SilverBullet.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=1.0.0" async></script><script type="text/javascript" src="//cdn.jsdelivr.net/gh/fancyapps/fancybox/dist/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=1.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox/dist/jquery.fancybox.min.css"><script type="text/javascript" src="/js/copycode.js" successtext="Copy Successed!"></script><link rel="stylesheet" type="text/css" href="/css/copycode.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=1.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=1.0.0"></script></div></body></html>